{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-groq langchain-community huggingface_hub PyPDF2 langchain_huggingface faiss-cpu dotenv gradio\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "import gradio as gr\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import io\n",
    "\n",
    "load_dotenv()\n",
    "login(os.getenv(\"hugging face key\"))\n",
    "\n",
    "# -------------------------------\n",
    "# Extract Text from PDF\n",
    "def get_pdf_text(pdf_file):\n",
    "    reader = PdfReader(pdf_file)\n",
    "    raw_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        if page.extract_text():\n",
    "            raw_text += page.extract_text()\n",
    "    return raw_text\n",
    "\n",
    "# -------------------------------\n",
    "# Text Chunking\n",
    "def get_text_chunks(raw_text):\n",
    "    splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len\n",
    "    )\n",
    "    return splitter.split_text(raw_text)\n",
    "\n",
    "# -------------------------------\n",
    "# Vector Store with HuggingFace Embeddings\n",
    "def get_vectorstore(chunks):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "# -------------------------------\n",
    "# LLM Setup\n",
    "from google.colab import userdata\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    temperature=0.7,\n",
    "    request_timeout=30,\n",
    "    api_key=\"grok Key\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# QA RAG Chain\n",
    "def create_qa_chain(vectorstore):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    You are a helpful assistant trained on product manuals.\n",
    "    Answer the user's question based on the context provided below.\n",
    "\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "# -------------------------------\n",
    "# QA Function for Gradio\n",
    "def product_manual_qa(pdf_file, user_question):\n",
    "    if not pdf_file or not user_question:\n",
    "        return \"‚ö† Please upload a PDF and enter a question.\"\n",
    "\n",
    "    raw_text = get_pdf_text(pdf_file)\n",
    "    chunks = get_text_chunks(raw_text)\n",
    "    vectorstore = get_vectorstore(chunks)\n",
    "    qa_chain = create_qa_chain(vectorstore)\n",
    "\n",
    "    return qa_chain.invoke(user_question)\n",
    "\n",
    "# -------------------------------\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## üìò Product Manual Question Answering System\")\n",
    "\n",
    "    with gr.Row():\n",
    "        pdf_input = gr.File(label=\"üìÑ Upload Product Manual PDF\", file_types=[\".pdf\"])\n",
    "        user_question = gr.Textbox(label=\"‚ùì Ask a Question about the Manual\")\n",
    "\n",
    "    submit_button = gr.Button(\"üîç Get Answer\")\n",
    "    answer_output = gr.Textbox(label=\"üì§ Answer\", lines=10)\n",
    "\n",
    "    submit_button.click(\n",
    "        fn=product_manual_qa,\n",
    "        inputs=[pdf_input, user_question],\n",
    "        outputs=answer_output\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
